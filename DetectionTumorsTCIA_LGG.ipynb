{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DetectionTumorsTCIA-LGG.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDBVqYlPISkx",
        "outputId": "654c77d0-58e2-4f9d-9633-8e26a1ad350b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I7MVcOQDEFI3",
        "outputId": "e8474f0a-e5a3-4dcc-dd41-e8568d413093"
      },
      "source": [
        "!pip install tensorflow-addons"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.14.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 4.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)\n",
            "Installing collected packages: tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.14.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djHi7EIaIM3i"
      },
      "source": [
        "import keras.backend as K\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "import os\n",
        "import math\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "import tensorflow as tf\n",
        "import scipy.io as sio\n",
        "import pandas as pd\n",
        "import time\n",
        "import cv2\n",
        "from skimage.transform import resize\n",
        "from IPython.display import clear_output"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTTzjJw0-4jd"
      },
      "source": [
        "def one_hot(vec):\n",
        "  items=np.sort(pd.unique(vec))\n",
        "  n_class=np.shape(items)[0]\n",
        "  zeros=np.zeros((vec.size, n_class))\n",
        "  for n,i in enumerate(items):\n",
        "    rows=np.where(vec==i)[0]\n",
        "    zeros[rows,n]=1\n",
        "  return zeros.astype('float32'), n_class"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jY318_Utj095"
      },
      "source": [
        "def get_index(vec_lab, seed=1996, split_train=0.6, validation=False):\n",
        "  train=[]\n",
        "  valid=[]\n",
        "  test =[]\n",
        "\n",
        "  spv=(1-split_train)/2.\n",
        "  for i in range(2):\n",
        "    ind_clss=np.where(vec_lab[:,i]==1)[0]\n",
        "    sz=len(ind_clss)\n",
        "    np.random.seed(seed)\n",
        "    ramd=np.random.choice(sz, sz, replace=False)\n",
        "    train=np.append(train, ind_clss[ramd[:int(sz*split_train)]])\n",
        "    valid=np.append(valid, ind_clss[ramd[int(sz*split_train):int(sz*(split_train+spv))]])\n",
        "    test =np.append(test, ind_clss[ramd[int(sz*(split_train+spv)):]])\n",
        "  train=train[np.random.choice(len(train), len(train), replace=False)].astype('int')\n",
        "  valid=valid[np.random.choice(len(valid), len(valid), replace=False)].astype('int')\n",
        "  test= test[np.random.choice(len(test), len(test), replace=False)].astype('int')\n",
        "  if validation:\n",
        "    return train, valid, test\n",
        "  else:\n",
        "    return np.concatenate((train,valid)), test"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ebtAOwgECsw"
      },
      "source": [
        "import tensorflow_addons as tfa\n",
        "def augmentation_f(data, labx):\n",
        "  images=tf.concat([data,\n",
        "                  tfa.image.rotate(data, angles=np.pi/2),\n",
        "                  tfa.image.rotate(data, angles=np.pi),\n",
        "                  tfa.image.rotate(data, angles=np.pi*3/2)], 0)\n",
        "  lab=tf.concat([labx,labx,labx,labx], 0)\n",
        "  sc=np.shape(images)[0]\n",
        "  idr=np.random.choice(sc,sc,replace=False)\n",
        "  images=tf.convert_to_tensor(np.array(images)[idr])\n",
        "  lab=tf.convert_to_tensor(np.array(lab)[idr])\n",
        "  return images, lab"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9fGugIcEwkA"
      },
      "source": [
        "def get_data_training(indx, ima_tens, labels_v, k_fold='none', number_folds=10, augm=False):\n",
        "  if k_fold!='none':\n",
        "    sz=len(indx)/number_folds\n",
        "    valid=indx[int(k_fold*sz):int((k_fold+1)*sz)]\n",
        "    train=np.concatenate((indx[:int(k_fold*sz)],indx[int((k_fold+1)*sz):])) \n",
        "\n",
        "    x_data=tf.image.grayscale_to_rgb(tf.convert_to_tensor(np.array(ima_tens)[train]))\n",
        "    v_data=tf.image.grayscale_to_rgb(tf.convert_to_tensor(np.array(ima_tens)[valid]))\n",
        "    y_data=tf.convert_to_tensor(np.array(labels_v)[train])\n",
        "    vy_dat=tf.convert_to_tensor(np.array(labels_v)[valid])\n",
        "\n",
        "    if augm:\n",
        "      x_data, y_data=augmentation_f(x_data, y_data)\n",
        "      v_data, vy_dat=augmentation_f(v_data, vy_dat)\n",
        "\n",
        "    return x_data, v_data, y_data, vy_dat\n",
        "  else:\n",
        "    x_data=tf.image.grayscale_to_rgb(tf.convert_to_tensor(np.array(ima_tens)[indx]))\n",
        "    y_data=tf.convert_to_tensor(np.array(labels_v)[indx])\n",
        "    if augm:\n",
        "      x_data, y_data=augmentation_f(x_data, y_data)\n",
        "    return x_data, y_data"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCy_IAjDgO5z"
      },
      "source": [
        "def get_data(sequences='T1'): #'FLAIR','T1_Gd'\n",
        "  data_dir=('/content/drive/MyDrive/Brain_tumors_v2/Datasets/TCIA_LGG/x_x.mat')\n",
        "  mats=sio.loadmat(data_dir.replace('x_x', sequences))\n",
        "  images=mats['images']\n",
        "  images=images.reshape((np.shape(images)[0],np.shape(images)[1],np.shape(images)[2],1))\n",
        "  labels=(mats['size_tumor'][0]!=0).astype('int')\n",
        "  images=tf.image.resize(images, [240,240], method='nearest')\n",
        "  labels, n_class=one_hot(labels)\n",
        "  return images, labels, n_class"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OrRZKTokAW-X"
      },
      "source": [
        "from tensorflow.keras import applications as ap\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_h7Ln2LyCOM"
      },
      "source": [
        "def get_model(network, opt='adadelta', loss_name='categorical_crossentropy', input_shape=(240,240,3), classes=2, weights='imagenet'):\n",
        "  try:\n",
        "    del model\n",
        "  except:\n",
        "    print('done')\n",
        "  model=Sequential()\n",
        "  if network=='ResNet50V2':\n",
        "    model.add(ap.ResNet50V2(include_top=False, weights=weights, input_shape=input_shape, pooling='avg', classes=classes)) # The input must have 3 channels\n",
        "  if network=='EfficientNetB7':\n",
        "    model.add(ap.EfficientNetB7(include_top=False, weights=weights, input_shape=input_shape, pooling='avg', classes=classes)) \n",
        "  if network=='InceptionResNetV2':\n",
        "    model.add(ap.InceptionResNetV2(include_top=False, weights=weights, input_shape=input_shape, pooling='avg', classes=classes)) \n",
        "  if network=='InceptionV3':\n",
        "    model.add(ap.InceptionV3(include_top=False, weights=weights, input_shape=input_shape, pooling='avg', classes=classes)) \n",
        "  if network=='NASNetLarge':\n",
        "    model.add(ap.NASNetLarge(include_top=False, weights=weights, input_shape=input_shape, pooling='avg', classes=classes))\n",
        "  if network=='VGG19':\n",
        "    model.add(ap.VGG19(include_top=False, weights=weights, input_shape=input_shape, pooling='avg', classes=classes)) \n",
        "  if network=='Xception':\n",
        "    model.add(ap.Xception(include_top=False, weights=weights, input_shape=input_shape, pooling='avg', classes=classes))\n",
        "  if network=='DenseNet121':\n",
        "    model.add(ap.DenseNet121(include_top=False, weights=weights, input_shape=input_shape, pooling='avg', classes=classes))\n",
        "  \n",
        "  model.add(Dense(classes, activation='softmax'))\n",
        "  model.compile(optimizer=opt, loss=loss_name, metrics=['acc', tf.keras.metrics.Recall(), tf.keras.metrics.FalsePositives()])\n",
        "  return model"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "id": "6DoCiB1QEEb-",
        "outputId": "0455b98b-535c-43ed-831f-4c2ac432612f"
      },
      "source": [
        "df = pd.DataFrame(columns=('run_n', 'k_fold', 'network', 'optimizer', 'loss', 'epochs', 'total_parameters', 'time', 'transfer', 'augm', 'Class', 'TP', 'TN', 'FP', 'FN','result_mat'))\n",
        "df.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>run_n</th>\n",
              "      <th>k_fold</th>\n",
              "      <th>network</th>\n",
              "      <th>optimizer</th>\n",
              "      <th>loss</th>\n",
              "      <th>epochs</th>\n",
              "      <th>total_parameters</th>\n",
              "      <th>time</th>\n",
              "      <th>transfer</th>\n",
              "      <th>augm</th>\n",
              "      <th>Class</th>\n",
              "      <th>TP</th>\n",
              "      <th>TN</th>\n",
              "      <th>FP</th>\n",
              "      <th>FN</th>\n",
              "      <th>result_mat</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [run_n, k_fold, network, optimizer, loss, epochs, total_parameters, time, transfer, augm, Class, TP, TN, FP, FN, result_mat]\n",
              "Index: []"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4sq7omoAW45"
      },
      "source": [
        "TP=tf.keras.metrics.TruePositives()\n",
        "TN=tf.keras.metrics.TrueNegatives()\n",
        "FP=tf.keras.metrics.FalsePositives()\n",
        "FN=tf.keras.metrics.FalseNegatives()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "elarYVjSCxnf"
      },
      "source": [
        "def run_experiment(images, labels, number_class, augm_con, name='', star_run=0, end_run=30, batch_size=4): \n",
        "  for net in Networks:\n",
        "    name_0='_'.join(['clasification_t', name, str(transferlearning), augm_con, net, optimizer])\n",
        "    if not os.path.exists(path2+name_0+'.csv'):\n",
        "      df.to_csv(path2+name_0+'.csv')\n",
        "\n",
        "    train_id, test_id=get_index(labels)\n",
        "    x_test, y_test=get_data_training(test_id, images, labels)\n",
        "    y_test=y_test>=0.5\n",
        "\n",
        "    for i in range(star_run, end_run): #Numero corridas \n",
        "      for j in [loss]: #Funciones de perdida\n",
        "        cntn=True\n",
        "        name_m='_'.join([name_0,j,'run',str(i)])  \n",
        "        print(name_m)\n",
        "\n",
        "        #Obtener imagenes nuevamente\n",
        "        x_train, x_valid, y_train, y_valid=get_data_training(train_id, images, labels, k_fold=i%10, augm=(augm_con!='None'))      \n",
        "        model=get_model(net, classes=number_class, input_shape=list(np.shape(x_train)[1:]),  weights=transferlearning)\n",
        "        \n",
        "        try:\n",
        "          tic = time.time()\n",
        "          results = model.fit(x_train, y_train, validation_data=(x_valid, y_valid), batch_size=batch_size, epochs=epochs)\n",
        "          toc=time.time()-tic\n",
        "          model.save_weights(pathW+name_m+\"w.h5\")\n",
        "        except:\n",
        "          print('Training error')\n",
        "          cntn=False\n",
        "\n",
        "        if cntn:\n",
        "          sio.savemat(pathW+name_m+'_r.mat', results.history)\n",
        "\n",
        "          #Validation\n",
        "          y_hat=np.array(model.predict(x_test))\n",
        "          sio.savemat(pathW+name_m+'_los_8.mat',{'y_hat': y_hat, 'y_test': np.array(y_test)})\n",
        "          y_hat=y_hat>=0.5\n",
        "\n",
        "          for class_i in range(number_class):\n",
        "            TP.reset_state()\n",
        "            TN.reset_state()\n",
        "            FP.reset_state()\n",
        "            FN.reset_state()        \n",
        "\n",
        "            TP.update_state(y_test[:,class_i], y_hat[:,class_i])\n",
        "            TN.update_state(y_test[:,class_i], y_hat[:,class_i])\n",
        "            FP.update_state(y_test[:,class_i], y_hat[:,class_i])\n",
        "            FN.update_state(y_test[:,class_i], y_hat[:,class_i])\n",
        "            total_p=model.count_params()\n",
        "\n",
        "            #data frame\n",
        "            df2=pd.read_csv(path2+name_0+'.csv')\n",
        "            df2=df2.append({'run_n': i,\n",
        "                            'k_fold': i%10,\n",
        "                            'network': net,\n",
        "                            'optimizer': optimizer,\n",
        "                            'loss': 'categorical_crossentropy',\n",
        "                            'epochs': epochs,\n",
        "                            'total_parameters': total_p,\n",
        "                            'time': toc,\n",
        "                            'transfer': transferlearning,\n",
        "                            'augm': augm_con,\n",
        "                            'Class': class_i,\n",
        "                            'TP': float(TP.result()),\n",
        "                            'TN': float(TN.result()),\n",
        "                            'FP': float(FP.result()),\n",
        "                            'FN': float(FN.result()),\n",
        "                            'result_mat': name_m+'_r.mat'} , ignore_index=True)\n",
        "            df2=df2.drop(df2.columns[:np.where(df2.columns=='run_n')[0][0]], axis=1)\n",
        "            df2.to_csv(path2+name_0+'.csv')\n",
        "          del x_train, y_train, x_valid, y_valid, model\n",
        "          clear_output(wait=True)\n",
        "    star_run=0"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQrrA6JqKeSz"
      },
      "source": [
        "# Run experiment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60hh25h9AW7g"
      },
      "source": [
        "Networks=['ResNet50V2', 'EfficientNetB7', 'InceptionResNetV2', 'InceptionV3', 'VGG19', 'Xception', 'DenseNet121']\n",
        "path2='/content/drive/MyDrive/Brain_tumors_v2/Results/TCIADetection/transfer/results_csv/'\n",
        "pathW='/content/drive/MyDrive/Brain_tumors_v2/Results/TCIADetection/transfer/Weights/'\n",
        "augmentation='None'\n",
        "transferlearning='imagenet'\n",
        "optimizer='adadelta'\n",
        "epochs=50\n",
        "loss='categorical_crossentropy'\n",
        "\n",
        "#----------------------------------RUN------------------------------------------\n",
        "seq='T1' #'FLAIR','T1_Gd'\n",
        "imas, labs, no_cls=get_data(seq)\n",
        "run_experiment(imas, labs, no_cls, augmentation, seq, star_run=0)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
